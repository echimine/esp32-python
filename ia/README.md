# FunctionGemma - Function Calling avec llama.cpp

Ce projet d√©montre l'utilisation de **FunctionGemma** (mod√®le Google optimis√© pour le function calling) via un serveur llama.cpp local.

## üìã Pr√©requis

- Python 3.10+
- [llama.cpp](https://github.com/ggerganov/llama.cpp) compil√©
- Le mod√®le quantis√© [functiongemma-270m-it-Q4_K_M.gguf](https://huggingface.co/unsloth/functiongemma-270m-it-GGUF)

### Installation des d√©pendances Python

```bash
pip install "openai>=1.3"
```

## üöÄ Lancement

### 1. D√©marrer le serveur llama.cpp

```bash
# Depuis le dossier llama.cpp
./build/bin/llama-server \
  -m /chemin/vers/functiongemma-270m-it-Q4_K_M.gguf \
  --host 127.0.0.1 \
  --port 8080 \
  --ctx-size 4096 \
  --threads 6
```

> **Mac Apple Silicon** : Ajouter `--gpu-layers 99` pour utiliser le GPU Metal.

### 2. Ex√©cuter le script

```bash
python function_gemma_llamacpp.py "Convertis 42 EUR en USD."
```

## üí° Exemples d'utilisation

```bash
# Conversion de devises
python function_gemma_llamacpp.py "Combien vaut 100 dollars en euros ?"

# Calcul de date
python function_gemma_llamacpp.py "Quelle date sera 30 jours apr√®s le 2026-01-15 ?"
```

## üîß Fonctions disponibles

| Fonction | Description | Param√®tres |
|----------|-------------|------------|
| `convert_currency` | Convertit un montant entre EUR et USD | `amount`, `currency_from`, `currency_to` |
| `add_days` | Ajoute des jours √† une date | `start_date` (YYYY-MM-DD), `days` |

## ‚öôÔ∏è Configuration

Variables d'environnement optionnelles :

```bash
export LLAMA_CPP_BASE_URL="http://127.0.0.1:8080/v1"
export LLAMA_CPP_API_KEY="devkey"
export LLAMA_CPP_MODEL="functiongemma-270m-it-Q4_K_M.gguf"
```

## üìÅ Structure du projet

```
.
‚îú‚îÄ‚îÄ function_gemma_llamacpp.py   # Script principal (llama.cpp)
‚îú‚îÄ‚îÄ function_gemma_runner.py     # Alternative via Transformers/HuggingFace
‚îú‚îÄ‚îÄ functiongemma-270m-it-Q4_K_M.gguf  # Mod√®le quantis√©
‚îî‚îÄ‚îÄ README.md
```

## üß† Comment √ßa marche

1. **Prompt structur√©** : Le script envoie un prompt avec les d√©clarations de fonctions au format JSON Schema
2. **G√©n√©ration contrainte** : Le mod√®le g√©n√®re un appel de fonction `{"name": "...", "parameters": {...}}`
3. **Ex√©cution locale** : Le script parse le JSON et ex√©cute la fonction Python correspondante
4. **R√©ponse format√©e** : Le r√©sultat est affich√© √† l'utilisateur

## ‚ö†Ô∏è Notes importantes

- **FunctionGemma 270M** est optimis√© pour le function calling, pas pour la g√©n√©ration de texte libre
- Le script utilise l'API `/completions` (pas `/chat/completions`) pour un meilleur contr√¥le du format
- Les taux de change sont fictifs (d√©mo uniquement)

## üìö Ressources

- [FunctionGemma sur HuggingFace](https://huggingface.co/google/functiongemma-270m-it)
- [llama.cpp](https://github.com/ggerganov/llama.cpp)
- [Documentation Gemma](https://ai.google.dev/gemma)
